#!/bin/bash

# In the root directory of a Python project repo, there is a script called `run`.
# This script prepares a few env vars, then run the current script.
#
# The code relies on `pyproject.toml` to specify dependencies and various project info.
# A Dockerfile is generated on the fly in this script.
# While building the image,
# the Python package being developed in the repo is installed with all its mandatory and optional
# dependencies; then the repo package itself is uninstalled, leaving the dependencies installed.
#
# The Docker image thus built is named zppz/<pkg>:dev
#
# Subsequent behavior depends on what Git branch is current.
#
# If branch is `main` or `master` or `release`,
# then all tests are run.
# If the branch is `release`, it further makes a release of the package.
# The release artifacts will appear in `dist/` under the root of the repo.
#
# If branch is any other, then it is assumed user is doing development.
# `run-docker` is then used to determine various `docker-run` settings and finally
# launch a container based on the newly built image, landing within the container
# ready for development testing. The repo directory is volume-mapped into the container,
# hence any test runs will use the latest code on the hosting machine.
# You can edit code outside of the container, then run tests inside the container.

# This script should be run from the root directory of the repo.
#
# This script does not use Python.
# Python is used while "building the Docker image"; in that context, Python is provided by the base image.


set -e


# In the real workflow, `$PARENT` is already defined in the script that calls the current script.
# Here we allow it to be missing so that the current script can be invoked directly
# during development and debugging of this script.
PARENT="${PARENT:-zppz/py3:24.12.16}"

if [[ $(uname -s) == Darwin && $(uname -p) == arm ]]; then
    # On Mac, we do not pull the parent image from a remote registry,
    # but rather require a locally-built one to exist, because
    # the remotely-stored images are for arm64 architecture only.
    if [[ $(docker images -q ${PARENT}) == '' ]]; then
        >&2 echo "Cannot find the parent image '${PARENT}'."
        exit 1
    fi
    if [[ $(docker image inspect -f "{{.Architecture}}" ${PARENT}) != arm64 ]]; then
        >&2 echo "The parent image '${PARENT}' on this machine is not optimized for the CPU architecture."
        exit 1
    fi
fi
echo "Parent image: ${PARENT}"


thisdir="$(cd $( pwd ) && pwd)"  # full path; do not use `${BASH_SOURCE[0]}` b/c this script is not invoked directly.
echo "Work directory: ${thisdir}"


# Infer the project name.
# This is the name of the parent directory, but we infer it from Git config to be more reliable.
proj="$(grep 'url = ' "${thisdir}"/.git/config)"  || proj="$(basename $(pwd))" # get the line like '   url = git@github.com:zpz/docker-mini.git'
proj="${proj##*/}"  # remove the longest substr from front of '/', keeping "docker-mini.git"
PROJ="${proj%.git}"  # remove substr from back
if [[ "${PROJ}" == *_* ]]; then
    >&2 "Project name '${PROJ}' contains underscore. Use dash instead."
    exit 1
fi
echo "Project: ${PROJ}"


# Infer the package name.
# This is the name of the package code directory under `src/`, also the "import" name.
# This does not need to be the "project" name defined in `pyproject.toml`, which is for `pypi` and `pip`,
# related to install/uninstall.
rm -rf "${thisdir}/src"/*egg-info  # these could have been created during package build
pkg="$(ls "${thisdir}"/src/)"
if [[ "${pkg}" == '' || $pkg = *' '* ]]; then  # zero or multiple subdirectories
    >&2 echo "unable to infer package name"
    exit 1
fi
PKG=${pkg%/}  # remove '/' at the end


# Infer branch name.
branch=$(cat "${thisdir}/.git/HEAD")
GITBRANCH=${branch##*refs/heads/}  # remove the longest substr from front
echo "Branch: ${GITBRANCH}"


DOCKER_SRCDIR=/tmp/src
# Copy project repo to this location in the image.

rm -f "${thisdir}"/Dockerfile
cat <<EOF >"${thisdir}"/Dockerfile
FROM ${PARENT}
USER root

ENV PARENT_IMAGE=${PARENT}

# If the repo needs non-Python dependencies, will need a mechanism
# to insert a block to install other things, or use user-defined Dockerfile.

# Install the package of the current repo along with all its required and optional
# dependencies. Then, uninstall the project package itself,
# leaving the dependencies in place. The source code is left in the image in order to run tests;
# otherwise it will be largely forgotten.
# Dev and test within the container will use volume-mapped live code.

ARG DOCKER_SRCDIR
COPY --chown=docker-user:docker-user . "${DOCKER_SRCDIR}"
ARG pyproj="${DOCKER_SRCDIR}/pyproject.toml"

RUN extras=\$(python -c "import toml; print(','.join(toml.load('\${pyproj}')['project']['optional-dependencies'].keys()))") \\
    && pip-install ${DOCKER_SRCDIR}/[\${extras}] \\
    && python -m pip uninstall -y \$(python -c "import toml; print(toml.load('\${pyproj}')['project']['name'])")

USER docker-user
EOF


docker build --no-cache -f "${thisdir}"/Dockerfile -t ${PROJ}:dev "${thisdir}"
echo

if [[ "${GITBRANCH}" == main || "${GITBRANCH}" == master || "${GITBRANCH}" == release ]]; then
    bash .githooks/pre-commit

    docker run --rm \
        -e IMAGE_NAME=${PROJ} \
        -e IMAGE_VERSION=dev \
        -e PKG="${PKG}" \
        -e PROJ="${PROJ}" \
        --workdir="${DOCKER_SRCDIR}" \
        -e PYTHONPATH="${DOCKER_SRCDIR}"/src \
        ${PROJ}:dev py.test --cov="src/${PKG}" "tests"

    if [[ "${GITBRANCH}" == release ]]; then
        rm -rf "${thisdir}/dist"

        docker rm "${PROJ}-release" &>/dev/null || true
        docker run \
            --workdir="${DOCKER_SRCDIR}" \
            --name="${PROJ}"-release \
            ${PROJ}:dev python -m build '.'
        docker cp "${PROJ}-release":"${DOCKER_SRCDIR}/dist" "${thisdir}"
        docker rm "${PROJ}-release"
        echo "Release artifacts are saved in '${thisdir}/dist'"
        # Successful release will create a `dist/*.tar.gz` and a `dist/*.whl`.
        # Outside of Docker, upload the package to PyPI by
        #   $ python3 -m twine upload dist/*
    fi
    rm -f "${thisdir}"/Dockerfile
else
    # Take a free ride to config githooks
    git config --local core.hooksPath "${thisdir}/.githooks/"
    chmod +x "${thisdir}/.githooks/pre-commit"

    rm -f "${thisdir}"/Dockerfile
    run-docker ${PROJ}:dev
fi
